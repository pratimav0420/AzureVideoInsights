{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "999af3ee",
   "metadata": {},
   "source": [
    "## Notebook to extract insights from video and using it to pass as context in prompt and chat with openai.\n",
    "\n",
    "### will be further worked upon to vectorize the transcript derived from the insights for large videos.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be3b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Constants and env variables.\n",
    "'''\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OpenAI_KEY=os.getenv('OpenAI_KEY')\n",
    "ASSISTANT_MODEL=os.getenv('ASSISTANT_MODEL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a90cf36",
   "metadata": {},
   "source": [
    "### Below are the helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56754ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def get_api_bearer_token():\n",
    "    '''\n",
    "    Function to get bearer token that can be used for getting access token for video indexing\n",
    "    '''\n",
    "\n",
    "    # Define the API endpoint\n",
    "    tenant_id =  os.getenv('AZURE_VIDEO_INDEXER_TENANT_ID')\n",
    "    url = f\"https://login.microsoftonline.com/{tenant_id}/oauth2/v2.0/token\"\n",
    "\n",
    "    # Prepare the data and files\n",
    "    client_id = os.getenv('AZURE_VIDEO_INDEXER_CLIENT_ID')\n",
    "    client_secret = os.getenv('AZURE_VIDEO_INDEXER_CLIENT_SECRET')\n",
    "    grant_type = \"client_credentials\"\n",
    "    scope = \"https://management.azure.com/.default\"\n",
    "\n",
    "    data = {\n",
    "        \"client_id\": client_id,\n",
    "        \"client_secret\": client_secret,\n",
    "        \"grant_type\": grant_type,\n",
    "        \"scope\": scope\n",
    "    }\n",
    "\n",
    "    # Send the request\n",
    "    response = requests.post(url, data=data)\n",
    "\n",
    "    # Handle the response\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['access_token']\n",
    "    else:\n",
    "        print(\"Failed to get bearer token\")\n",
    "        print(\"Status code:\", response.status_code)\n",
    "        print(\"Response:\", response.text)\n",
    "\n",
    "def get_access_token():\n",
    "    '''\n",
    "    Function to get bearer token that can be used for getting access token for video indexing\n",
    "    '''\n",
    "    subscription_id = os.getenv('AZURE_VIDEO_INDEXER_SUBSCRIPTION_ID')\n",
    "    resource_group = os.getenv('AZURE_VIDEO_INDEXER_RESOURCE_GROUP')\n",
    "    account_name = os.getenv('AZURE_VIDEO_INDEXER_ACCOUNT_NAME')\n",
    "    version = '2022-08-01'\n",
    "\n",
    "    url = f\"https://management.azure.com/subscriptions/{subscription_id}/resourcegroups/{resource_group}/providers/Microsoft.VideoIndexer/accounts/{account_name}/generateAccessToken?api-version={version}\"\n",
    "    \n",
    "    data = {\n",
    "        \"permissionType\": \"Contributor\",\n",
    "        \"scope\": \"Account\"\n",
    "    }\n",
    "\n",
    "    bearer_token = get_api_bearer_token()\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": 'application/json',\n",
    "        \"Authorization\": f\"Bearer {bearer_token}\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()['accessToken']\n",
    "    else:\n",
    "        print(\"Failed to get access token\")\n",
    "        print(\"Status code:\", response.status_code)\n",
    "        print(\"Response:\", response.text)\n",
    "\n",
    "def get_video_insights(video_id):\n",
    "    account_id = os.getenv('AZURE_VIDEO_INDEXER_ACCOUNT_ID')\n",
    "    location = os.getenv('AZURE_VIDEO_INDEXER_LOCATION', 'eastus')\n",
    "    access_token = get_access_token()\n",
    "\n",
    "    url = f\"https://api.videoindexer.ai/eastus/Accounts/{account_id}/Videos/{video_id}/Index?accessToken={access_token}\"\n",
    "    \n",
    "    \n",
    "    params = {\n",
    "        'accessToken': access_token\n",
    "    }\n",
    "\n",
    "    print(f'Fetching insights for video {video_id}...')\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    video_insights_data = response.json().get('videos', [])[0]\n",
    "    return video_insights_data\n",
    "\n",
    "def parse_insights(video_insights):\n",
    "    \n",
    "    insights = video_insights.get('insights')\n",
    "    transcript = \" \".join([t[\"text\"] for t in insights.get(\"transcript\", [])])\n",
    "    faces = [f[\"name\"] for f in insights.get(\"faces\", []) if f.get(\"name\") != \"Unknown\"]\n",
    "    keywords = [k[\"text\"] for k in insights.get(\"keywords\", [])]\n",
    "    topics = [t[\"name\"] for t in insights.get(\"topics\", [])]\n",
    "    emotions = [e[\"type\"] for e in insights.get(\"emotions\", [])]\n",
    "\n",
    "    return {\n",
    "        \"videoId\": video_insights.get(\"id\"),\n",
    "        \"transcript\": transcript,\n",
    "        \"faces\": faces,\n",
    "        \"keywords\": keywords,\n",
    "        \"topics\": topics,\n",
    "        \"emotions\": emotions\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5fa2f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching insights for video 2wur8zc1t2...\n",
      "This video (ID: 2wur8zc1t2)Key themes in this video include: Technology, Computer S, Application Programming Interfaces Api, Database Systems. Notable keywords extracted are: building agent, mcp server, data sources, code assistant, chat app, mcp client, mcp host, mcp protocol, server, servers, and more. Detected individuals or faces in the video: Unknown #1, Unknown #2. Below is the full transcript of the video:\n",
      "\n",
      "If you're building AI agents, you've probably heard about MCP, or Model Context Protocol. MCP is a new open source standard to connect your agents to data sources such as databases or APIs. MCP consists of multiple components. The most important ones are the host, the client, and the server. So let's break it down. At the very top, you would have your MCP host. Your MCP host will include an MCP client, and it could also include multiple clients. The MCP host could be an application such as a chat app, it could also be a code assistant in your IDE, and much more. The MCP host will connect to an MCP server. It can actually connect to multiple MCP servers as well. It doesn't matter how many MCP servers you connect to your MCP host or client. The MCP host and servers will connect over each other through the MCP protocol. The MCP protocol is a transport layer in the middle. Whenever your MCP host or client needs a tool, it's going to connect to the MCP server. The MCP server will then connect to for example a database and it doesn't matter if this is a relational database or a no SQL database. It could also connect to APIs and also the API standard doesn't really matter. Finally, it could also connect to data sources, such as a local file type or maybe code. This is especially useful when you're building something like a code assistant in your IDE. Let's look at an example of how to use MCP in practice. We still have the three components. We would have our MCP host and client. Of course, we also have a large language model. And finally we have our MCP servers and these could be multiple MCP servers or just a single one. Let's assume more MCP client and host as a chat app and you ask a question such as what is the weather like in a certain location or how many customers do I have? The MCP host will need to retrieve tools from the MCP server. The MCP server will then conclude and tell which tools are available from the MCP host. You wouldn't have to connect to the large language model and send over your question plus the available tools. If all is well, the LM will reply and tell you which tools to use. Once the MCP host and client knows which tools to use, it knows which MCP servers to call. So when it calls the MCP server in order to get a tool result, the MCP server will be responsible for executing something that goes to a database, to an API or a local piece of code. And of course there could be subsequent calls to MCP servers. The MCP server will apply with a response which you can send back to the LLM. And finally, you should be able to get your final answer based on the question that you asked in each other application. If you are building agent, I would really advise you to look at MCP protocol. The MCP protocol is a new standard which will help you to connect your data sources via MCP server to any agent. Even though you might not be building agents, your client might be building agents. And if you enjoyed this video, make sure to like and subscribe.\n"
     ]
    }
   ],
   "source": [
    "raw = get_video_insights('2wur8zc1t2')\n",
    "doc = parse_insights(raw)\n",
    "with open('output.json', 'w', encoding='utf-8') as f:\n",
    "  json.dump(doc, f, indent=4)\n",
    "\n",
    "context_template = (\n",
    "    \"This video (ID: {video_id})\"\n",
    "    \"Key themes in this video include: {topics}. \"\n",
    "    \"Notable keywords extracted are: {keywords}. \"\n",
    "    \"Detected individuals or faces in the video: {faces}. \"\n",
    "    \"Below is the full transcript of the video:\\n\\n{transcript}\"\n",
    ")\n",
    "\n",
    "context = context_template.format(\n",
    "  video_id=doc[\"videoId\"],\n",
    "  topics=', '.join(doc[\"topics\"]) if doc[\"topics\"] else \"None\",\n",
    "  keywords=', '.join(doc[\"keywords\"][:10]) + (\", and more\" if len(doc[\"keywords\"]) > 10 else \"\"),\n",
    "  faces=', '.join(doc[\"faces\"]) if doc[\"faces\"] else \"None\",\n",
    "  transcript=doc[\"transcript\"]\n",
    ")\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cee5dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "# Your context variable (assumed to be a long string prepared earlier)\n",
    "# context = build_context(data)\n",
    "\n",
    "def ask_question_with_context(user_question, context):\n",
    "\n",
    "    client = OpenAI(api_key=OpenAI_KEY)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",  # or \"gpt-3.5-turbo\" if you're using that\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are a helpful assistant. Use ONLY the provided context to answer the user's question. \"\n",
    "                    \"Do not rely on any outside knowledge or make assumptions beyond the context. \"\n",
    "                    \"If the answer cannot be found in the context, reply with: 'The context does not contain that information.'\"\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Context:\\n{context}\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Question: {user_question}\"\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79e86494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The MCP server is a component of the Model Context Protocol (MCP), which is a new open source standard used to connect agents to data sources such as databases or APIs. The MCP server connects to the MCP host or client when they need a tool. It can connect to a database, whether it's a relational database or a no SQL database, APIs, or data sources like a local file type or code. The MCP server is responsible for executing something that goes to a database, to an API or a local piece of code when it is called by the MCP host or client to get a tool result. It can also be connected to multiple MCP hosts or clients.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_question_with_context('Tell me about MCP server', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "286fd267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The context does not contain that information.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_question_with_context('Tell me India', context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
